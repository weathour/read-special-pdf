{
  "file_name": "Esser 等 - Scaling Rectified Flow Transformers for High-Resolution Image Synthesis.pdf",
  "generated_at": "2025-07-11 00:37:57",
  "structured_info": {
    "title_cn": "扩展整流流变换器用于高分辨率图像合成",
    "title_en": "Scaling Rectified Flow Transformers for High-Resolution Image Synthesis",
    "category": "Computer Vision",
    "topics": [
      "Generative Modeling",
      "Text-to-Image Synthesis",
      "Diffusion Models"
    ],
    "keywords": [
      "Rectified Flow",
      "Diffusion Models",
      "Transformer Architecture",
      "Text-to-Image Generation",
      "Scaling Laws"
    ],
    "abstract": "Diffusion models create data from noise by inverting the forward paths of data towards noise and have emerged as a powerful generative modeling technique for high-dimensional, perceptual data such as images and videos. Rectified flow is a recent generative model formulation that connects data and noise in a straight line. Despite its better theoretical properties and conceptual simplicity, it is not yet decisively established as standard practice. In this work, we improve existing noise sampling techniques for training rectified flow models by biasing them towards perceptually relevant scales. Through a large-scale study, we demonstrate the superior performance of this approach compared to established diffusion formulations for high-resolution text-to-image synthesis. Additionally, we present a novel transformer-based architecture for text-to-image generation that uses separate weights for the two modalities and enables a bidirectional flow of information between image and text tokens, improving text comprehension, typography, and human preference ratings. We demonstrate that this architecture follows predictable scaling trends and correlates lower validation loss to improved text-to-image synthesis as measured by various metrics and human evaluations. Our largest models outperform state-of-the-art models.",
    "methodology": "Rectified flow formulation with improved noise sampling techniques (logit-normal and mode samplers), novel multimodal transformer architecture (MM-DiT) with separate weights for image/text modalities, latent diffusion with enhanced autoencoders (16 channels), and large-scale scaling studies. Training uses AdamW optimizer with mixed-precision and EMA weights.",
    "conclusion": "The proposed rectified flow formulation with perceptually biased noise sampling outperforms standard diffusion models, especially in few-step sampling regimes. The MM-DiT architecture enables superior text comprehension and image quality. Scaling studies show predictable trends where lower validation loss correlates with improved human preference and benchmark metrics (GenEval, T2I-CompBench). The largest 8B model surpasses state-of-art models like DALL-E 3 and SDXL.",
    "authors": [
      "Patrick Esser",
      "Sumith Kulal",
      "Andreas Blattmann",
      "Rahim Entezari",
      "Jonas Müller",
      "Harry Saini",
      "Yam Levi",
      "Dominik Lorenz",
      "Axel Sauer",
      "Frederic Boesel",
      "Dustin Podell",
      "Tim Dockhorn",
      "Zion English",
      "Robin Rombach"
    ],
    "publication_year": "2024",
    "venue": "Proceedings of the 41st International Conference on Machine Learning (ICML)",
    "doi": "",
    "bibtex_citation": "Esser_Scaling_2024",
    "analysis": {
      "Overview": "Introduces improvements to rectified flow models for high-resolution text-to-image synthesis, including novel noise sampling techniques and a transformer architecture (MM-DiT), validated through large-scale experiments showing predictable scaling behavior.",
      "Background_and_Motivation": [
        "Diffusion models dominate perceptual data generation but suffer from computational costs and sampling inefficiencies due to curved probability paths.",
        "Rectified flow's theoretical advantages (straight paths enabling single-step sampling) are underexplored for text-to-image tasks, and existing architectures inadequately handle multimodal interactions.",
        "Authors argue rectified flow's efficiency is critical for practical applications, highlighting artifacts in diffusion models (e.g., gray images from residual noise) and suboptimal text conditioning in transformers.",
        "The work bridges efficient generative modeling and high-fidelity text-to-image synthesis, addressing scalability gaps in rectified flows.",
        "Contributes to generative modeling, computer vision, and multimodal machine learning."
      ],
      "Conceptual_Framework_and_Innovations": [
        "Rectified Flow: Straight-path ODE connecting data and noise distributions; MM-DiT: Transformer with separate weights for image/text tokens enabling bidirectional attention; Perceptual Noise Sampling: Biased sampling (e.g., logit-normal) toward perceptually critical intermediate timesteps.",
        "Noise sampling refines rectified flow training; MM-DiT leverages refined flows for enhanced text-image alignment; together they enable scalable high-resolution synthesis.",
        "Straight paths are optimal for fast sampling; scaling transformer depth/width predictably improves performance; synthetic+original captions improve text fidelity.",
        "Provides empirical framework for rectified flows in text-to-image tasks, establishes noise sampling as superior to diffusion baselines, and introduces architecture for multimodal fusion."
      ],
      "Methodology": [
        "Core methods include rectified flow with logit-normal/mode samplers, MM-DiT architecture (separate weights per modality, RMSNorm stabilization), latent diffusion with 16-channel autoencoders, and scaling studies up to 8B parameters.",
        "Novelty: First large-scale rectified flow application to text-to-image; logit-normal sampling addresses uniform sampling limitations; MM-DiT outperforms DiT/UViT. Applicability: Demonstrated for images/videos. Rationality: Validation loss correlates with human evaluations.",
        "Datasets: ImageNet, CC12M, COCO; synthetic captions via CogVLM (50% mix). Preprocessing: Autoencoder latent space, deduplication, NSFW/aesthetic filtering. Representativeness: Captions improved spatial/textual alignment; high-resolution finetuning addressed aspect ratios.",
        "Rigorous comparison of 61 formulations across noise samplers/architectures; metrics include FID, CLIP, GenEval, T2I-CompBench, and human preference; ablation studies validate design choices.",
        "Aligns with flow matching theory (Lipman et al.) and diffusion paradigms; transformer scaling follows vision-language trends (Dehghani et al.)."
      ],
      "Results": [
        "Rectified flow with logit-normal sampling (m=0, s=1) outperforms EDM/LDM in FID/CLIP, especially at low sampling steps. MM-DiT surpasses DiT/UViT in convergence speed and metrics. Scaling: Lower validation loss predicts improved human preference (r=0.94). 8B model beats DALL-E 3/SDXL in GenEval and typography.",
        "Results are reliable (consistent across datasets/samplers) and stable (EMA weights improve metrics). Significance: Establishes rectified flow as viable for text-to-image, demonstrates architecture scalability, and validates noise sampling innovation."
      ],
      "Argumentation_and_Logic": [
        "Structured: Problem (diffusion limitations) → Solution (rectified flow + MM-DiT) → Validation (scaling studies) → Superiority (benchmarks/human eval).",
        "Key steps: Theoretical motivation for straight paths; noise sampler ablation; architecture comparison; scaling laws; SOTA comparison. Logical links: Samplers improve flow efficiency → MM-DiT exploits efficiency for modality fusion → Scaling amplifies gains.",
        "Strengths: Comprehensive experiments (61 formulations); end-to-end validation. Weaknesses: Limited video results; computational cost. Rebuttals: Address sampling instability via QK normalization; mitigate caption bias with synthetic data."
      ],
      "Strengths_and_Limitations": [
        "Strengths: Novel noise samplers and MM-DiT; first rectified flow text-to-image SOTA; predictable scaling; open-sourcing intent.",
        "Limitations: High VRAM demands; no theoretical optimality proof for paths; reliance on pretrained autoencoders.",
        "Straight-path assumption simplifies ODEs but may not capture complex data manifolds; scaling trends assume transformer-centric architectures."
      ],
      "Academic_Discourse_and_Rhetoric": [
        "Positions rectified flow as underutilized alternative to diffusion models; frames MM-DiT as necessary for true multimodal fusion.",
        "Technical terminology (e.g., 'conditional flow matching', 'path curvature'); assertive tone emphasizing empirical superiority; rhetorical emphasis on scalability and human preference.",
        "Builds authority via citations to foundational works (Ho et al., Lipman et al.); strategic comparisons to SOTA (DALL-E 3, SDXL) to highlight contributions."
      ],
      "Conclusions_and_Implications": [
        "Conclusions: Rectified flow with perceptual noise sampling outperforms diffusion models; MM-DiT enables scalable text-to-image synthesis; validation loss predicts downstream performance; 8B model achieves SOTA.",
        "Future work: Explore video synthesis, theoretical analysis of straight paths, distillation for efficiency, and ethical deployment frameworks."
      ]
    }
  }
}