
# pdf_json_checker/pdf_manager.py
"""
PDFç­›é€‰ä¸ç®¡ç†æ¨¡å—
åŸºäºpapers.dbæ•°æ®åº“è¿›è¡ŒPDFæ–‡ä»¶ç®¡ç†
"""

import sqlite3
import json
import os
import shutil
from pathlib import Path
from typing import List, Dict, Set, Tuple, Optional
import logging
from datetime import datetime
from dataclasses import dataclass

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class PDFStatus:
    """PDFçŠ¶æ€ä¿¡æ¯"""
    file_name: str
    has_json: bool
    has_pdf: bool
    json_path: Optional[str] = None
    pdf_path: Optional[str] = None
    paper_id: Optional[int] = None

class PDFManager:
    """PDFæ–‡ä»¶ç®¡ç†å™¨"""
    
    def __init__(self, db_path: str = "../papers.db", pdf_base_dir: str = "../pdfs"):
        """
        åˆå§‹åŒ–PDFç®¡ç†å™¨
        Args:
            db_path: papers.dbæ•°æ®åº“è·¯å¾„
            pdf_base_dir: PDFæ–‡ä»¶åŸºç¡€ç›®å½•
        """
        self.db_path = Path(db_path).resolve()
        self.pdf_base_dir = Path(pdf_base_dir).resolve()
        
        # åˆ›å»ºPDFç›®å½•ç»“æ„
        self.pdf_base_dir.mkdir(parents=True, exist_ok=True)
        
        # éªŒè¯æ•°æ®åº“è¿æ¥
        self._verify_database()
        
        logger.info(f"âœ… PDFç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"ğŸ“ æ•°æ®åº“è·¯å¾„: {self.db_path}")
        logger.info(f"ğŸ“ PDFç›®å½•: {self.pdf_base_dir}")
    
    def _verify_database(self):
        """éªŒè¯æ•°æ®åº“è¿æ¥"""
        if not self.db_path.exists():
            raise FileNotFoundError(f"æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {self.db_path}")
        
        try:
            conn = sqlite3.connect(str(self.db_path))
            cursor = conn.cursor()
            cursor.execute("SELECT COUNT(*) FROM papers")
            count = cursor.fetchone()[0]
            conn.close()
            logger.info(f"ğŸ“Š æ•°æ®åº“è¿æ¥æˆåŠŸï¼Œå…±æœ‰ {count} ç¯‡è®ºæ–‡")
        except Exception as e:
            raise Exception(f"æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
    
    def get_papers_from_db(self) -> List[Dict]:
        """ä»æ•°æ®åº“è·å–æ‰€æœ‰è®ºæ–‡ä¿¡æ¯"""
        conn = sqlite3.connect(str(self.db_path))
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT id, file_name, title_cn, title_en, authors, 
                   publication_year, venue, json_path, created_at
            FROM papers
            ORDER BY id
        ''')
        
        papers = [dict(row) for row in cursor.fetchall()]
        conn.close()
        
        logger.info(f"ğŸ“š ä»æ•°æ®åº“è·å– {len(papers)} ç¯‡è®ºæ–‡")
        return papers
    
    def scan_pdf_directory(self, scan_subdirs: bool = True) -> List[Path]:
        """æ‰«æPDFç›®å½•ï¼Œè·å–æ‰€æœ‰PDFæ–‡ä»¶"""
        pdf_files = []
        
        if scan_subdirs:
            # é€’å½’æ‰«æå­ç›®å½•
            pdf_files = list(self.pdf_base_dir.rglob("*.pdf"))
        else:
            # åªæ‰«ææ ¹ç›®å½•
            pdf_files = list(self.pdf_base_dir.glob("*.pdf"))
        
        logger.info(f"ğŸ” æ‰«æåˆ° {len(pdf_files)} ä¸ªPDFæ–‡ä»¶")
        return pdf_files
    
    def extract_basename(self, file_path: str) -> str:
        """æå–æ–‡ä»¶åŸºç¡€åï¼ˆå»é™¤æ‰©å±•åï¼‰"""
        return Path(file_path).stem
    
    def find_pdf_for_paper(self, paper: Dict) -> Optional[Path]:
        """ä¸ºæ•°æ®åº“ä¸­çš„è®ºæ–‡æŸ¥æ‰¾å¯¹åº”çš„PDFæ–‡ä»¶"""
        file_name = paper.get('file_name', '')
        if not file_name:
            return None
        
        # æå–åŸºç¡€æ–‡ä»¶å
        base_name = self.extract_basename(file_name)
        
        # å¯èƒ½çš„PDFæ–‡ä»¶åæ¨¡å¼
        possible_names = [
            f"{base_name}.pdf",
            f"{file_name}.pdf" if not file_name.endswith('.pdf') else file_name,
            f"{base_name}_original.pdf",
            f"{base_name}_processed.pdf"
        ]
        
        # åœ¨PDFç›®å½•ä¸­æœç´¢
        for pdf_file in self.scan_pdf_directory():
            if pdf_file.name in possible_names:
                return pdf_file
            
            # æ¨¡ç³ŠåŒ¹é…ï¼ˆå»é™¤ç‰¹æ®Šå­—ç¬¦åæ¯”è¾ƒï¼‰
            pdf_base = self.normalize_filename(pdf_file.stem)
            paper_base = self.normalize_filename(base_name)
            
            if pdf_base == paper_base:
                return pdf_file
        
        return None
    
    def normalize_filename(self, filename: str) -> str:
        """æ ‡å‡†åŒ–æ–‡ä»¶åï¼Œç”¨äºæ¨¡ç³ŠåŒ¹é…"""
        import re
        # ç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼Œè½¬å°å†™
        normalized = re.sub(r'[^\w\s-]', '', filename.lower())
        # ç§»é™¤å¤šä½™ç©ºæ ¼å’Œä¸‹åˆ’çº¿
        normalized = re.sub(r'[\s_-]+', '', normalized)
        return normalized.strip()
    
    def find_json_for_pdf(self, pdf_path: Path, papers: List[Dict]) -> Optional[Dict]:
        """ä¸ºPDFæ–‡ä»¶æŸ¥æ‰¾å¯¹åº”çš„JSONè®°å½•"""
        pdf_base = self.normalize_filename(pdf_path.stem)
        
        for paper in papers:
            file_name = paper.get('file_name', '')
            if not file_name:
                continue
            
            # æ ‡å‡†åŒ–æ¯”è¾ƒ
            paper_base = self.normalize_filename(self.extract_basename(file_name))
            
            if pdf_base == paper_base:
                return paper
        
        return None
    
    def generate_status_report(self) -> Dict:
        """ç”ŸæˆPDFçŠ¶æ€æŠ¥å‘Š"""
        logger.info("ğŸ” å¼€å§‹ç”ŸæˆPDFçŠ¶æ€æŠ¥å‘Š...")
        
        # è·å–æ•°æ®åº“ä¸­çš„è®ºæ–‡
        papers = self.get_papers_from_db()
        
        # æ‰«æPDFæ–‡ä»¶
        pdf_files = self.scan_pdf_directory()
        
        # åˆ†æçŠ¶æ€
        status_list = []
        
        # 1. æ£€æŸ¥æ¯ç¯‡è®ºæ–‡çš„PDFçŠ¶æ€
        logger.info("ğŸ“Š æ£€æŸ¥è®ºæ–‡çš„PDFçŠ¶æ€...")
        for paper in papers:
            pdf_path = self.find_pdf_for_paper(paper)
            
            status = PDFStatus(
                file_name=paper.get('file_name', ''),
                has_json=True,  # æ•°æ®åº“ä¸­çš„éƒ½æœ‰JSON
                has_pdf=pdf_path is not None,
                json_path=paper.get('json_path', ''),
                pdf_path=str(pdf_path) if pdf_path else None,
                paper_id=paper.get('id')
            )
            status_list.append(status)
        
        # 2. æ£€æŸ¥å­¤ç«‹çš„PDFæ–‡ä»¶ï¼ˆæ²¡æœ‰å¯¹åº”JSONçš„ï¼‰
        logger.info("ğŸ” æ£€æŸ¥å­¤ç«‹çš„PDFæ–‡ä»¶...")
        matched_pdfs = {status.pdf_path for status in status_list if status.has_pdf}
        
        for pdf_file in pdf_files:
            if str(pdf_file) not in matched_pdfs:
                status = PDFStatus(
                    file_name=pdf_file.name,
                    has_json=False,
                    has_pdf=True,
                    pdf_path=str(pdf_file)
                )
                status_list.append(status)
        
        # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
        stats = {
            'total_papers_in_db': len(papers),
            'total_pdf_files': len(pdf_files),
            'papers_with_pdf': sum(1 for s in status_list if s.has_json and s.has_pdf),
            'papers_without_pdf': sum(1 for s in status_list if s.has_json and not s.has_pdf),
            'orphaned_pdfs': sum(1 for s in status_list if not s.has_json and s.has_pdf),
            'match_rate': 0.0
        }
        
        if stats['total_papers_in_db'] > 0:
            stats['match_rate'] = stats['papers_with_pdf'] / stats['total_papers_in_db'] * 100
        
        report = {
            'generated_at': datetime.now().isoformat(),
            'statistics': stats,
            'status_list': status_list,
            'pdf_directory': str(self.pdf_base_dir),
            'database_path': str(self.db_path)
        }
        
        logger.info("âœ… PDFçŠ¶æ€æŠ¥å‘Šç”Ÿæˆå®Œæˆ")
        self._print_status_summary(stats)
        
        return report
    
    def _print_status_summary(self, stats: Dict):
        """æ‰“å°çŠ¶æ€æ‘˜è¦"""
        print("\n" + "="*60)
        print("ğŸ“Š PDFæ–‡ä»¶çŠ¶æ€ç»Ÿè®¡")
        print("="*60)
        print(f"ğŸ“š æ•°æ®åº“ä¸­è®ºæ–‡æ€»æ•°: {stats['total_papers_in_db']}")
        print(f"ğŸ“„ PDFæ–‡ä»¶æ€»æ•°: {stats['total_pdf_files']}")
        print(f"âœ… æœ‰å¯¹åº”PDFçš„è®ºæ–‡: {stats['papers_with_pdf']}")
        print(f"âŒ ç¼ºå°‘PDFçš„è®ºæ–‡: {stats['papers_without_pdf']}")
        print(f"ğŸ” å­¤ç«‹çš„PDFæ–‡ä»¶: {stats['orphaned_pdfs']}")
        print(f"ğŸ“ˆ åŒ¹é…ç‡: {stats['match_rate']:.1f}%")
        print("="*60)
    
    def list_missing_pdfs(self) -> List[Dict]:
        """åˆ—å‡ºç¼ºå°‘PDFçš„è®ºæ–‡"""
        report = self.generate_status_report()
        
        missing_pdfs = []
        for status in report['status_list']:
            if status.has_json and not status.has_pdf:
                # ä»æ•°æ®åº“è·å–è¯¦ç»†ä¿¡æ¯
                conn = sqlite3.connect(str(self.db_path))
                conn.row_factory = sqlite3.Row
                cursor = conn.cursor()
                
                cursor.execute('''
                    SELECT id, title_cn, title_en, authors, venue, publication_year
                    FROM papers WHERE id = ?
                ''', (status.paper_id,))
                
                paper = cursor.fetchone()
                conn.close()
                
                if paper:
                    missing_pdfs.append({
                        'id': paper['id'],
                        'file_name': status.file_name,
                        'title_cn': paper['title_cn'],
                        'title_en': paper['title_en'],
                        'authors': paper['authors'],
                        'venue': paper['venue'],
                        'publication_year': paper['publication_year']
                    })
        
        return missing_pdfs
    
    def list_orphaned_pdfs(self) -> List[Dict]:
        """åˆ—å‡ºå­¤ç«‹çš„PDFæ–‡ä»¶ï¼ˆæ²¡æœ‰å¯¹åº”JSONçš„ï¼‰"""
        report = self.generate_status_report()
        
        orphaned_pdfs = []
        for status in report['status_list']:
            if not status.has_json and status.has_pdf:
                pdf_path = Path(status.pdf_path)
                orphaned_pdfs.append({
                    'file_name': status.file_name,
                    'file_path': status.pdf_path,
                    'file_size': pdf_path.stat().st_size if pdf_path.exists() else 0,
                    'last_modified': datetime.fromtimestamp(pdf_path.stat().st_mtime).isoformat() if pdf_path.exists() else None
                })
        
        return orphaned_pdfs
    
    def organize_pdfs_by_status(self, output_dir: str):
        """æŒ‰çŠ¶æ€ç»„ç»‡PDFæ–‡ä»¶"""
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        # åˆ›å»ºå­ç›®å½•
        matched_dir = output_path / "matched_pdfs"
        orphaned_dir = output_path / "orphaned_pdfs"
        
        matched_dir.mkdir(exist_ok=True)
        orphaned_dir.mkdir(exist_ok=True)
        
        report = self.generate_status_report()
        
        copied_matched = 0
        copied_orphaned = 0
        
        for status in report['status_list']:
            if status.has_pdf:
                src_path = Path(status.pdf_path)
                
                if status.has_json:
                    # æœ‰å¯¹åº”JSONçš„PDF
                    dst_path = matched_dir / src_path.name
                    shutil.copy2(src_path, dst_path)
                    copied_matched += 1
                else:
                    # å­¤ç«‹çš„PDF
                    dst_path = orphaned_dir / src_path.name
                    shutil.copy2(src_path, dst_path)
                    copied_orphaned += 1
        
        logger.info(f"ğŸ“ PDFæ–‡ä»¶ç»„ç»‡å®Œæˆ:")
        logger.info(f"  - åŒ¹é…çš„PDF: {copied_matched} ä¸ª -> {matched_dir}")
        logger.info(f"  - å­¤ç«‹çš„PDF: {copied_orphaned} ä¸ª -> {orphaned_dir}")
        
        return {
            'matched_count': copied_matched,
            'orphaned_count': copied_orphaned,
            'matched_dir': str(matched_dir),
            'orphaned_dir': str(orphaned_dir)
        }
    
    def save_report(self, report: Dict, output_file: str):
        """ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶"""
        output_path = Path(output_file)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        # è½¬æ¢PDFStatuså¯¹è±¡ä¸ºå­—å…¸
        serializable_report = report.copy()
        serializable_report['status_list'] = [
            {
                'file_name': status.file_name,
                'has_json': status.has_json,
                'has_pdf': status.has_pdf,
                'json_path': status.json_path,
                'pdf_path': status.pdf_path,
                'paper_id': status.paper_id
            }
            for status in report['status_list']
        ]
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(serializable_report, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ğŸ’¾ æŠ¥å‘Šå·²ä¿å­˜: {output_path}")

# ä½¿ç”¨ç¤ºä¾‹å’Œæµ‹è¯•å‡½æ•°
def test_pdf_manager():
    """æµ‹è¯•PDFç®¡ç†å™¨åŠŸèƒ½"""
    manager = PDFManager()
    
    # ç”ŸæˆçŠ¶æ€æŠ¥å‘Š
    report = manager.generate_status_report()
    
    # åˆ—å‡ºç¼ºå°‘PDFçš„è®ºæ–‡
    missing = manager.list_missing_pdfs()
    print(f"\nâŒ ç¼ºå°‘PDFçš„è®ºæ–‡: {len(missing)} ç¯‡")
    for paper in missing[:5]:  # æ˜¾ç¤ºå‰5ç¯‡
        print(f"  - {paper['title_en'][:50]}...")
    
    # åˆ—å‡ºå­¤ç«‹çš„PDF
    orphaned = manager.list_orphaned_pdfs()
    print(f"\nğŸ” å­¤ç«‹çš„PDFæ–‡ä»¶: {len(orphaned)} ä¸ª")
    for pdf in orphaned[:5]:  # æ˜¾ç¤ºå‰5ä¸ª
        print(f"  - {pdf['file_name']}")

if __name__ == "__main__":
    test_pdf_manager()
