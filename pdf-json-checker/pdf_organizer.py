
# pdf_json_checker/pdf_organizer.py
"""
PDFæ•´ç†å™¨
ç”Ÿæˆåˆ†ææŠ¥å‘Šçš„åŒæ—¶å¤åˆ¶PDFæ–‡ä»¶åˆ°å¯¹åº”ç›®å½•
"""

import json
import shutil
from pathlib import Path
from typing import Dict, List
import logging
from datetime import datetime

from pdf_manager import PDFManager

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class PDFOrganizer:
    """PDFæ•´ç†å™¨ - åˆ†æ + å¤åˆ¶æ–‡ä»¶"""
    
    def __init__(self, db_path: str = "../papers.db", pdf_base_dir: str = "/home/jia/snap/zotero-snap/common/Zotero/storage"):
        """
        åˆå§‹åŒ–PDFæ•´ç†å™¨
        Args:
            db_path: papers.dbæ•°æ®åº“è·¯å¾„
            pdf_base_dir: PDFæ–‡ä»¶åŸºç¡€ç›®å½•
        """
        self.pdf_manager = PDFManager(db_path, pdf_base_dir)
        logger.info("ğŸš€ PDFæ•´ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def organize_and_copy(self, output_dir: str = "./output") -> Dict:
        """
        æ•´ç†å¹¶å¤åˆ¶PDFæ–‡ä»¶
        Args:
            output_dir: è¾“å‡ºç›®å½•
        Returns:
            å¤„ç†ç»“æœç»Ÿè®¡
        """
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        logger.info(f"ğŸ“Š å¼€å§‹æ•´ç†PDFæ–‡ä»¶åˆ°: {output_path}")
        
        # 1. ç”ŸæˆçŠ¶æ€æŠ¥å‘Š
        logger.info("ğŸ“‹ ç”ŸæˆPDFçŠ¶æ€æŠ¥å‘Š...")
        report = self.pdf_manager.generate_status_report()
        
        # 2. åˆ›å»ºå­ç›®å½•
        matched_pdfs_dir = output_path / "matched_pdfs"
        orphaned_pdfs_dir = output_path / "orphaned_pdfs"
        
        matched_pdfs_dir.mkdir(exist_ok=True)
        orphaned_pdfs_dir.mkdir(exist_ok=True)
        
        # 3. è·å–å„ç±»PDFåˆ—è¡¨
        missing_pdfs = self.pdf_manager.list_missing_pdfs()
        orphaned_pdfs = self.pdf_manager.list_orphaned_pdfs()
        
        # 4. ä¿å­˜JSONæŠ¥å‘Š
        self._save_json_reports(output_path, report, missing_pdfs, orphaned_pdfs)
        
        # 5. å¤åˆ¶PDFæ–‡ä»¶
        copy_stats = self._copy_pdf_files(report, matched_pdfs_dir, orphaned_pdfs_dir)
        
        # 6. ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
        summary = self._generate_summary(copy_stats, missing_pdfs, orphaned_pdfs)
        
        # 7. ä¿å­˜æ±‡æ€»æŠ¥å‘Š
        self._save_summary_report(output_path, summary)
        
        logger.info("ğŸ‰ PDFæ•´ç†å®Œæˆ!")
        self._print_summary(summary)
        
        return summary
    
    def _save_json_reports(self, output_path: Path, report: Dict, missing_pdfs: List, orphaned_pdfs: List):
        """ä¿å­˜JSONæŠ¥å‘Šæ–‡ä»¶"""
        logger.info("ğŸ’¾ ä¿å­˜JSONæŠ¥å‘Šæ–‡ä»¶...")
        
        # 1. å®Œæ•´çŠ¶æ€æŠ¥å‘Š
        self.pdf_manager.save_report(report, output_path / "pdf_status_report.json")
        
        # 2. ç¼ºå°‘PDFçš„è®ºæ–‡åˆ—è¡¨
        with open(output_path / "missing_pdfs.json", 'w', encoding='utf-8') as f:
            json.dump(missing_pdfs, f, indent=2, ensure_ascii=False)
        
        # 3. å­¤ç«‹çš„PDFåˆ—è¡¨
        with open(output_path / "orphaned_pdfs.json", 'w', encoding='utf-8') as f:
            json.dump(orphaned_pdfs, f, indent=2, ensure_ascii=False)
        
        logger.info(f"âœ… JSONæŠ¥å‘Šå·²ä¿å­˜: {len(missing_pdfs)} ç¼ºå¤±, {len(orphaned_pdfs)} å­¤ç«‹")
    
    def _copy_pdf_files(self, report: Dict, matched_dir: Path, orphaned_dir: Path) -> Dict:
        """å¤åˆ¶PDFæ–‡ä»¶åˆ°å¯¹åº”ç›®å½•"""
        logger.info("ğŸ“ å¼€å§‹å¤åˆ¶PDFæ–‡ä»¶...")
        
        copy_stats = {
            'matched_copied': 0,
            'matched_failed': 0,
            'orphaned_copied': 0,
            'orphaned_failed': 0,
            'matched_files': [],
            'orphaned_files': [],
            'failed_files': []
        }
        
        for status in report['status_list']:
            if status.has_pdf:
                src_path = Path(status.pdf_path)
                
                try:
                    if status.has_json:
                        # æœ‰å¯¹åº”JSONçš„PDF -> matched_pdfsç›®å½•
                        dst_path = matched_dir / src_path.name
                        shutil.copy2(src_path, dst_path)
                        copy_stats['matched_copied'] += 1
                        copy_stats['matched_files'].append({
                            'file_name': src_path.name,
                            'src_path': str(src_path),
                            'dst_path': str(dst_path),
                            'paper_id': status.paper_id
                        })
                        logger.debug(f"  âœ… å¤åˆ¶matched: {src_path.name}")
                        
                    else:
                        # å­¤ç«‹çš„PDF -> orphaned_pdfsç›®å½•
                        dst_path = orphaned_dir / src_path.name
                        shutil.copy2(src_path, dst_path)
                        copy_stats['orphaned_copied'] += 1
                        copy_stats['orphaned_files'].append({
                            'file_name': src_path.name,
                            'src_path': str(src_path),
                            'dst_path': str(dst_path)
                        })
                        logger.debug(f"  ğŸ” å¤åˆ¶orphaned: {src_path.name}")
                        
                except Exception as e:
                    logger.error(f"âŒ å¤åˆ¶å¤±è´¥: {src_path.name} - {e}")
                    if status.has_json:
                        copy_stats['matched_failed'] += 1
                    else:
                        copy_stats['orphaned_failed'] += 1
                    
                    copy_stats['failed_files'].append({
                        'file_name': src_path.name,
                        'src_path': str(src_path),
                        'error': str(e)
                    })
        
        logger.info(f"ğŸ“ æ–‡ä»¶å¤åˆ¶å®Œæˆ: matched={copy_stats['matched_copied']}, orphaned={copy_stats['orphaned_copied']}")
        return copy_stats
    
    def _generate_summary(self, copy_stats: Dict, missing_pdfs: List, orphaned_pdfs: List) -> Dict:
        """ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š"""
        total_papers = len(self.pdf_manager.get_papers_from_db())
        
        summary = {
            'generated_at': datetime.now().isoformat(),
            'total_papers_in_db': total_papers,
            'statistics': {
                'matched_pdfs': {
                    'count': copy_stats['matched_copied'],
                    'failed': copy_stats['matched_failed'],
                    'success_rate': copy_stats['matched_copied'] / max(copy_stats['matched_copied'] + copy_stats['matched_failed'], 1) * 100
                },
                'orphaned_pdfs': {
                    'count': copy_stats['orphaned_copied'],
                    'failed': copy_stats['orphaned_failed'],
                    'success_rate': copy_stats['orphaned_copied'] / max(copy_stats['orphaned_copied'] + copy_stats['orphaned_failed'], 1) * 100
                },
                'missing_pdfs': {
                    'count': len(missing_pdfs),
                    'percentage': len(missing_pdfs) / max(total_papers, 1) * 100
                },
                'overall': {
                    'total_pdf_files': copy_stats['matched_copied'] + copy_stats['orphaned_copied'],
                    'match_rate': copy_stats['matched_copied'] / max(total_papers, 1) * 100,
                    'coverage_rate': (copy_stats['matched_copied'] + copy_stats['orphaned_copied']) / max(total_papers, 1) * 100
                }
            },
            'file_details': {
                'matched_files': copy_stats['matched_files'],
                'orphaned_files': copy_stats['orphaned_files'],
                'failed_files': copy_stats['failed_files']
            }
        }
        
        return summary
    
    def _save_summary_report(self, output_path: Path, summary: Dict):
        """ä¿å­˜æ±‡æ€»æŠ¥å‘Š"""
        # ä¿å­˜è¯¦ç»†æ±‡æ€»æŠ¥å‘Š
        with open(output_path / "organization_summary.json", 'w', encoding='utf-8') as f:
            json.dump(summary, f, indent=2, ensure_ascii=False)
        
        # ä¿å­˜ç®€åŒ–çš„ç»Ÿè®¡æŠ¥å‘Š
        simple_stats = {
            'generated_at': summary['generated_at'],
            'total_papers_in_db': summary['total_papers_in_db'],
            'matched_pdfs_count': summary['statistics']['matched_pdfs']['count'],
            'orphaned_pdfs_count': summary['statistics']['orphaned_pdfs']['count'],
            'missing_pdfs_count': summary['statistics']['missing_pdfs']['count'],
            'match_rate': f"{summary['statistics']['overall']['match_rate']:.1f}%",
            'directories': {
                'matched_pdfs': "./matched_pdfs/",
                'orphaned_pdfs': "./orphaned_pdfs/"
            }
        }
        
        with open(output_path / "simple_statistics.json", 'w', encoding='utf-8') as f:
            json.dump(simple_stats, f, indent=2, ensure_ascii=False)
        
        logger.info("ğŸ“Š æ±‡æ€»æŠ¥å‘Šå·²ä¿å­˜")
    
    def _print_summary(self, summary: Dict):
        """æ‰“å°æ±‡æ€»ä¿¡æ¯"""
        stats = summary['statistics']
        
        print(f"\n{'='*60}")
        print("ğŸ“Š PDFæ•´ç†æ±‡æ€»æŠ¥å‘Š")
        print(f"{'='*60}")
        print(f"ğŸ•’ å¤„ç†æ—¶é—´: {summary['generated_at']}")
        print(f"ğŸ“š æ•°æ®åº“è®ºæ–‡æ€»æ•°: {summary['total_papers_in_db']}")
        print(f"")
        print(f"ğŸ“ æ–‡ä»¶åˆ†å¸ƒ:")
        print(f"  âœ… åŒ¹é…çš„PDF: {stats['matched_pdfs']['count']} ä¸ª")
        print(f"     â†’ å¤åˆ¶åˆ°: ./matched_pdfs/")
        print(f"  ğŸ” å­¤ç«‹çš„PDF: {stats['orphaned_pdfs']['count']} ä¸ª")
        print(f"     â†’ å¤åˆ¶åˆ°: ./orphaned_pdfs/")
        print(f"  âŒ ç¼ºå¤±çš„PDF: {stats['missing_pdfs']['count']} ä¸ª")
        print(f"     â†’ è¯¦è§: missing_pdfs.json")
        print(f"")
        print(f"ğŸ“ˆ ç»Ÿè®¡æŒ‡æ ‡:")
        print(f"  åŒ¹é…ç‡: {stats['overall']['match_rate']:.1f}%")
        print(f"  è¦†ç›–ç‡: {stats['overall']['coverage_rate']:.1f}%")
        print(f"  æ€»PDFæ–‡ä»¶: {stats['overall']['total_pdf_files']} ä¸ª")
        
        if stats['matched_pdfs']['failed'] > 0 or stats['orphaned_pdfs']['failed'] > 0:
            print(f"")
            print(f"âš ï¸  å¤åˆ¶å¤±è´¥:")
            print(f"  åŒ¹é…PDFå¤±è´¥: {stats['matched_pdfs']['failed']} ä¸ª")
            print(f"  å­¤ç«‹PDFå¤±è´¥: {stats['orphaned_pdfs']['failed']} ä¸ª")
        
        print(f"{'='*60}")
    
    def list_files_in_directory(self, output_dir: str = "./output"):
        """åˆ—å‡ºæ•´ç†åçš„æ–‡ä»¶ç»“æ„"""
        output_path = Path(output_dir)
        
        if not output_path.exists():
            logger.error(f"è¾“å‡ºç›®å½•ä¸å­˜åœ¨: {output_path}")
            return
        
        print(f"\nğŸ“ æ•´ç†åçš„æ–‡ä»¶ç»“æ„:")
        print(f"ğŸ“‚ {output_path}/")
        
        # JSONæ–‡ä»¶
        json_files = list(output_path.glob("*.json"))
        for json_file in sorted(json_files):
            file_size = json_file.stat().st_size / 1024  # KB
            print(f"  ğŸ“„ {json_file.name} ({file_size:.1f} KB)")
        
        # PDFç›®å½•
        for subdir in ['matched_pdfs', 'orphaned_pdfs']:
            subdir_path = output_path / subdir
            if subdir_path.exists():
                pdf_files = list(subdir_path.glob("*.pdf"))
                total_size = sum(f.stat().st_size for f in pdf_files) / 1024 / 1024  # MB
                print(f"  ğŸ“‚ {subdir}/ ({len(pdf_files)} files, {total_size:.1f} MB)")
                
                # æ˜¾ç¤ºå‰å‡ ä¸ªæ–‡ä»¶
                for pdf_file in sorted(pdf_files)[:3]:
                    file_size = pdf_file.stat().st_size / 1024 / 1024  # MB
                    print(f"    ğŸ“„ {pdf_file.name} ({file_size:.1f} MB)")
                
                if len(pdf_files) > 3:
                    print(f"    ... è¿˜æœ‰ {len(pdf_files) - 3} ä¸ªæ–‡ä»¶")

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='PDFæ•´ç†å™¨')
    parser.add_argument('--db-path', default='../papers.db', help='æ•°æ®åº“è·¯å¾„')
    parser.add_argument('--pdf-dir', default='../pdfs', help='PDFåŸºç¡€ç›®å½•')
    parser.add_argument('--output-dir', default='./output', help='è¾“å‡ºç›®å½•')
    parser.add_argument('--list-files', action='store_true', help='åˆ—å‡ºæ•´ç†åçš„æ–‡ä»¶')
    
    args = parser.parse_args()
    
    try:
        organizer = PDFOrganizer(args.db_path, args.pdf_dir)
        
        if args.list_files:
            # åªåˆ—å‡ºæ–‡ä»¶
            organizer.list_files_in_directory(args.output_dir)
        else:
            # æ‰§è¡Œæ•´ç†
            organizer.organize_and_copy(args.output_dir)
            
    except Exception as e:
        logger.error(f"âŒ æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
