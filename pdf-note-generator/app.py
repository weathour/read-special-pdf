
# app.py - ä¿®å¤ç‰ˆFlask Webç•Œé¢
import os
import sys
import json
import shutil
import threading
import time
from pathlib import Path
from datetime import datetime
from flask import Flask, render_template, request, jsonify, send_file, flash, redirect, url_for, session
from werkzeug.utils import secure_filename
import zipfile
import io

# å¯¼å…¥æ‚¨çš„ç°æœ‰æ¨¡å—
from main_optimized import OptimizedPDFNoteGenerator
from config import load_config, save_config
from file_manager import FileManager

app = Flask(__name__)
app.secret_key = 'your-secret-key-change-this-in-production'
app.config['UPLOAD_FOLDER'] = 'uploads'
app.config['OUTPUT_FOLDER'] = 'web_outputs'
app.config['MAX_CONTENT_LENGTH'] = 500 * 1024 * 1024  # 500MB max file size

# å…¨å±€å˜é‡ç”¨äºè·Ÿè¸ªå¤„ç†çŠ¶æ€
processing_status = {
    'is_processing': False,
    'current_file': '',
    'progress': 0,
    'total_files': 0,
    'processed_files': 0,
    'failed_files': 0,
    'skipped_files': 0,  # æ–°å¢ï¼šè·³è¿‡çš„æ–‡ä»¶æ•°
    'message': '',
    'start_time': None,
    'elapsed_time': 0,
    'logs': [],
    'should_stop': False,
    'output_folder': None
}

# ç¡®ä¿å¿…è¦çš„æ–‡ä»¶å¤¹å­˜åœ¨
os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)
os.makedirs(app.config['OUTPUT_FOLDER'], exist_ok=True)

class WebProgressCallback:
    """Webè¿›åº¦å›è°ƒç±»"""
    def __init__(self):
        self.logs = []
    
    def update_progress(self, current, total, message=""):
        global processing_status
        processing_status['progress'] = int((current / total) * 100) if total > 0 else 0
        processing_status['current_file'] = message
        processing_status['processed_files'] = current
        processing_status['total_files'] = total
        
        # è®¡ç®—è¿è¡Œæ—¶é—´
        if processing_status['start_time']:
            processing_status['elapsed_time'] = time.time() - processing_status['start_time']
        
        log_entry = {
            'timestamp': datetime.now().strftime('%H:%M:%S'),
            'message': f"å¤„ç†è¿›åº¦: {current}/{total} - {message}"
        }
        processing_status['logs'].append(log_entry)
        
        # ä¿æŒæ—¥å¿—æ•°é‡ä¸è¶…è¿‡100æ¡
        if len(processing_status['logs']) > 100:
            processing_status['logs'] = processing_status['logs'][-100:]

@app.route('/')
def index():
    """ä¸»é¡µé¢"""
    return render_template('index.html')

@app.route('/config')
def config_page():
    """é…ç½®é¡µé¢"""
    config = load_config('config.json')
    return render_template('config.html', config=config)

@app.route('/save_config', methods=['POST'])
def save_config_route():
    """ä¿å­˜é…ç½®"""
    try:
        config_data = request.json
        save_config('config.json', config_data)
        return jsonify({'success': True, 'message': 'é…ç½®ä¿å­˜æˆåŠŸ'})
    except Exception as e:
        return jsonify({'success': False, 'message': f'é…ç½®ä¿å­˜å¤±è´¥: {str(e)}'})

@app.route('/scan_folder', methods=['POST'])
def scan_folder():
    """æ‰«ææ–‡ä»¶å¤¹ä¸­çš„PDFæ–‡ä»¶ï¼ˆé€’å½’æ‰«æï¼‰å¹¶æ£€æŸ¥å¤„ç†çŠ¶æ€"""
    try:
        data = request.json
        folder_path = data.get('folder_path', '').strip()
        
        if not folder_path:
            return jsonify({'success': False, 'message': 'è¯·è¾“å…¥æ–‡ä»¶å¤¹è·¯å¾„'})
        
        folder_path = Path(folder_path)
        if not folder_path.exists():
            return jsonify({'success': False, 'message': 'æ–‡ä»¶å¤¹ä¸å­˜åœ¨'})
        
        if not folder_path.is_dir():
            return jsonify({'success': False, 'message': 'è·¯å¾„ä¸æ˜¯æ–‡ä»¶å¤¹'})
        
        # ä½¿ç”¨é€’å½’æ‰«æPDFæ–‡ä»¶ï¼Œä¸åŸå§‹ä»£ç ä¸€è‡´
        pdf_files = []
        try:
            for pattern in ['*.pdf', '*.PDF']:
                pdf_files.extend(folder_path.rglob(pattern))  # ä½¿ç”¨rglobè¿›è¡Œé€’å½’æ‰«æ
            pdf_files = sorted(list(set(pdf_files)))
        except Exception as e:
            return jsonify({'success': False, 'message': f'æ‰«ææ–‡ä»¶æ—¶å‡ºé”™: {str(e)}'})
        
        if not pdf_files:
            return jsonify({'success': False, 'message': 'æ–‡ä»¶å¤¹ä¸­æ²¡æœ‰æ‰¾åˆ°PDFæ–‡ä»¶ï¼ˆåŒ…æ‹¬å­æ–‡ä»¶å¤¹ï¼‰'})
        
        # åŠ è½½é…ç½®ä»¥è®¡ç®—é…ç½®å“ˆå¸Œ
        config = load_config('config.json')
        file_manager = FileManager()
        config_hash = file_manager.calculate_config_hash(config)
        
        # æ•´ç†æ–‡ä»¶ä¿¡æ¯ï¼ŒåŒ…æ‹¬å­æ–‡ä»¶å¤¹ä¿¡æ¯å’Œå¤„ç†çŠ¶æ€
        file_info = []
        directories = {}
        total_size = 0
        processed_count = 0
        new_count = 0
        config_changed_count = 0
        
        for pdf_file in pdf_files:
            try:
                # è®¡ç®—ç›¸å¯¹è·¯å¾„
                rel_path = pdf_file.relative_to(folder_path)
                parent_dir = str(rel_path.parent) if rel_path.parent != Path('.') else 'æ ¹ç›®å½•'
                
                file_size = pdf_file.stat().st_size
                
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å¤„ç†
                existing_record = file_manager.is_file_processed(pdf_file, config_hash)
                
                status = 'new'
                status_text = 'æ–°æ–‡ä»¶'
                
                if existing_record:
                    if existing_record.get('config_changed', False):
                        status = 'config_changed'
                        status_text = 'é…ç½®å·²æ›´æ”¹'
                        config_changed_count += 1
                    elif existing_record.get('output_json_path') and not Path(existing_record['output_json_path']).exists():
                        status = 'output_missing'
                        status_text = 'è¾“å‡ºæ–‡ä»¶ä¸¢å¤±'
                        config_changed_count += 1
                    else:
                        status = 'processed'
                        status_text = 'å·²å¤„ç†'
                        processed_count += 1
                else:
                    new_count += 1
                
                file_info.append({
                    'name': pdf_file.name,
                    'path': str(pdf_file),
                    'relative_path': str(rel_path),
                    'parent_dir': parent_dir,
                    'size': file_size,
                    'size_mb': round(file_size / 1024 / 1024, 2),
                    'status': status,
                    'status_text': status_text
                })
                
                # ç»Ÿè®¡æ–‡ä»¶å¤¹ä¿¡æ¯
                if parent_dir not in directories:
                    directories[parent_dir] = {'count': 0, 'size': 0}
                directories[parent_dir]['count'] += 1
                directories[parent_dir]['size'] += file_size
                total_size += file_size
            except Exception as e:
                print(f"å¤„ç†æ–‡ä»¶ {pdf_file} æ—¶å‡ºé”™: {e}")
                continue
        
        # æŒ‰æ–‡ä»¶åæ’åº
        file_info.sort(key=lambda x: x['name'])
        
        session['scanned_folder'] = str(folder_path)
        session['scanned_files'] = file_info
        
        # æ„é€ è¯¦ç»†çš„è¿”å›æ¶ˆæ¯
        need_process_count = new_count + config_changed_count
        
        return jsonify({
            'success': True,
            'message': f'æ‰«æå®Œæˆï¼æ€»å…±æ‰¾åˆ° {len(file_info)} ä¸ªPDFæ–‡ä»¶ï¼Œå·²å¤„ç† {processed_count} ä¸ªï¼Œéœ€è¦å¤„ç† {need_process_count} ä¸ª',
            'files': file_info,
            'folder_path': str(folder_path),
            'directories': directories,
            'total_size': total_size,
            'total_size_mb': round(total_size / 1024 / 1024, 2),
            'processing_summary': {
                'total_files': len(file_info),
                'processed_files': processed_count,
                'new_files': new_count,
                'config_changed_files': config_changed_count,
                'need_process_files': need_process_count
            }
        })
        
    except Exception as e:
        return jsonify({'success': False, 'message': f'æ‰«æå¤±è´¥: {str(e)}'})

@app.route('/check_duplicates', methods=['POST'])
def check_duplicates():
    """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å¤„ç†è¿‡"""
    try:
        data = request.json
        files = data.get('files', [])
        
        if not files:
            return jsonify({'success': False, 'message': 'æ²¡æœ‰æä¾›æ–‡ä»¶åˆ—è¡¨'})
        
        # åŠ è½½é…ç½®ä»¥è®¡ç®—é…ç½®å“ˆå¸Œ
        config = load_config('config.json')
        file_manager = FileManager()
        config_hash = file_manager.calculate_config_hash(config)
        
        file_status = []
        total_files = len(files)
        new_files = 0
        processed_files = 0
        config_changed_files = 0
        
        for file_info in files:
            file_path = Path(file_info['path'])
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å¤„ç†
            existing_record = file_manager.is_file_processed(file_path, config_hash)
            
            status = {
                'path': str(file_path),
                'name': file_path.name,
                'size_mb': file_info.get('size_mb', 0),
                'processed': False,
                'config_changed': False,
                'output_missing': False,
                'skip_reason': None
            }
            
            if existing_record:
                status['processed'] = True
                
                if existing_record.get('config_changed', False):
                    status['config_changed'] = True
                    status['skip_reason'] = 'é…ç½®å·²æ›´æ”¹'
                    config_changed_files += 1
                elif existing_record.get('output_json_path') and not Path(existing_record['output_json_path']).exists():
                    status['output_missing'] = True
                    status['skip_reason'] = 'è¾“å‡ºæ–‡ä»¶ä¸¢å¤±'
                    config_changed_files += 1
                else:
                    status['skip_reason'] = 'å·²å¤„ç†'
                    processed_files += 1
            else:
                new_files += 1
            
            file_status.append(status)
        
        return jsonify({
            'success': True,
            'file_status': file_status,
            'summary': {
                'total_files': total_files,
                'new_files': new_files,
                'processed_files': processed_files,
                'config_changed_files': config_changed_files,
                'files_to_process': new_files + config_changed_files
            }
        })
        
    except Exception as e:
        return jsonify({'success': False, 'message': f'æ£€æŸ¥å¤±è´¥: {str(e)}'})

@app.route('/upload', methods=['POST'])
def upload_files():
    """ä¸Šä¼ PDFæ–‡ä»¶"""
    if 'files' not in request.files:
        return jsonify({'success': False, 'message': 'æ²¡æœ‰é€‰æ‹©æ–‡ä»¶'})
    
    files = request.files.getlist('files')
    if not files or files[0].filename == '':
        return jsonify({'success': False, 'message': 'æ²¡æœ‰é€‰æ‹©æ–‡ä»¶'})
    
    uploaded_files = []
    upload_folder = Path(app.config['UPLOAD_FOLDER'])
    
    # åˆ›å»ºå½“å‰ä¸Šä¼ çš„æ—¶é—´æˆ³æ–‡ä»¶å¤¹
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    current_upload_folder = upload_folder / timestamp
    current_upload_folder.mkdir(exist_ok=True)
    
    try:
        for file in files:
            if file and file.filename.lower().endswith('.pdf'):
                filename = secure_filename(file.filename)
                filepath = current_upload_folder / filename
                file.save(str(filepath))
                uploaded_files.append({
                    'name': filename,
                    'size': filepath.stat().st_size,
                    'path': str(filepath)
                })
        
        session['current_upload_folder'] = str(current_upload_folder)
        return jsonify({
            'success': True, 
            'message': f'æˆåŠŸä¸Šä¼  {len(uploaded_files)} ä¸ªæ–‡ä»¶',
            'files': uploaded_files,
            'upload_folder': str(current_upload_folder)
        })
        
    except Exception as e:
        return jsonify({'success': False, 'message': f'æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {str(e)}'})

@app.route('/process', methods=['POST'])
def process_files():
    """å¤„ç†PDFæ–‡ä»¶"""
    global processing_status
    
    if processing_status['is_processing']:
        return jsonify({'success': False, 'message': 'æ­£åœ¨å¤„ç†ä¸­ï¼Œè¯·ç¨å€™'})
    
    try:
        data = request.json
        input_folder = data.get('input_folder', '').strip()
        output_folder = data.get('output_folder', '').strip()
        force_reprocess = data.get('force_reprocess', False)
        use_scanned_folder = data.get('use_scanned_folder', False)
        
        # ç¡®å®šè¾“å…¥æ–‡ä»¶å¤¹
        if use_scanned_folder:
            input_folder = session.get('scanned_folder')
        elif not input_folder:
            input_folder = session.get('current_upload_folder')
        
        if not input_folder or not Path(input_folder).exists():
            return jsonify({'success': False, 'message': 'è¾“å…¥æ–‡ä»¶å¤¹ä¸å­˜åœ¨æˆ–æœªæŒ‡å®š'})
        
        # ç¡®å®šè¾“å‡ºæ–‡ä»¶å¤¹
        if not output_folder:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            output_folder = str(Path(app.config['OUTPUT_FOLDER']) / f"output_{timestamp}")
        
        # åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹
        output_path = Path(output_folder)
        output_path.mkdir(parents=True, exist_ok=True)
        
        # é‡ç½®å¤„ç†çŠ¶æ€
        processing_status.update({
            'is_processing': True,
            'current_file': '',
            'progress': 0,
            'total_files': 0,
            'processed_files': 0,
            'failed_files': 0,
            'skipped_files': 0,
            'message': 'æ­£åœ¨åˆå§‹åŒ–...',
            'start_time': time.time(),
            'elapsed_time': 0,
            'logs': [],
            'should_stop': False,
            'output_folder': str(output_path)
        })
        
        # åœ¨åå°çº¿ç¨‹ä¸­å¤„ç†
        thread = threading.Thread(
            target=background_process,
            args=(input_folder, output_path, force_reprocess)
        )
        thread.daemon = True
        thread.start()
        
        session['current_output_folder'] = str(output_path)
        
        return jsonify({
            'success': True,
            'message': 'å¤„ç†å·²å¼€å§‹',
            'output_folder': str(output_path)
        })
        
    except Exception as e:
        processing_status['is_processing'] = False
        return jsonify({'success': False, 'message': f'å¤„ç†å¯åŠ¨å¤±è´¥: {str(e)}'})

@app.route('/stop_processing', methods=['POST'])
def stop_processing():
    """åœæ­¢å¤„ç†"""
    global processing_status
    
    if not processing_status['is_processing']:
        return jsonify({'success': False, 'message': 'å½“å‰æ²¡æœ‰æ­£åœ¨å¤„ç†çš„ä»»åŠ¡'})
    
    processing_status['should_stop'] = True
    
    log_entry = {
        'timestamp': datetime.now().strftime('%H:%M:%S'),
        'message': 'ğŸ›‘ ç”¨æˆ·è¯·æ±‚åœæ­¢å¤„ç†...'
    }
    processing_status['logs'].append(log_entry)
    
    return jsonify({'success': True, 'message': 'æ­£åœ¨åœæ­¢å¤„ç†...'})

def background_process(input_folder, output_folder, force_reprocess):
    """åå°å¤„ç†å‡½æ•°"""
    global processing_status
    
    try:
        # åŠ è½½é…ç½®
        config = load_config('config.json')
        
        # åˆ›å»ºå¤„ç†å™¨ï¼Œä½¿ç”¨åŸå§‹å¤„ç†é€»è¾‘
        processor = OptimizedPDFNoteGenerator(config)
        
        # è·å–å¤„ç†ç»Ÿè®¡ä¿¡æ¯
        original_process_directory = processor.process_directory
        
        def enhanced_process_directory(input_dir, output_dir, force_reprocess=False):
            """å¢å¼ºçš„å¤„ç†ç›®å½•æ–¹æ³•ï¼Œé›†æˆWebçŠ¶æ€æ›´æ–°"""
            
            # æ‰«ææ–‡ä»¶
            log_entry = {
                'timestamp': datetime.now().strftime('%H:%M:%S'),
                'message': f'ğŸ” å¼€å§‹æ‰«æPDFæ–‡ä»¶: {input_dir}'
            }
            processing_status['logs'].append(log_entry)
            
            pdf_files = processor._get_all_pdf_files(Path(input_dir))
            
            if not pdf_files:
                processing_status['message'] = 'æ²¡æœ‰æ‰¾åˆ°PDFæ–‡ä»¶'
                return {'total_files': 0, 'processed_files': 0, 'failed_files': 0, 'skipped_files': 0}
            
            processing_status['total_files'] = len(pdf_files)
            
            log_entry = {
                'timestamp': datetime.now().strftime('%H:%M:%S'),
                'message': f'ğŸ“‹ æ‰¾åˆ° {len(pdf_files)} ä¸ªPDFæ–‡ä»¶'
            }
            processing_status['logs'].append(log_entry)
            
            # æ˜¾ç¤ºæ–‡ä»¶åˆ†å¸ƒ
            processor._show_file_distribution(pdf_files, Path(input_dir))
            
            # è¿‡æ»¤éœ€è¦å¤„ç†çš„æ–‡ä»¶
            if not force_reprocess:
                log_entry = {
                    'timestamp': datetime.now().strftime('%H:%M:%S'),
                    'message': 'ğŸ”„ æ£€æŸ¥å·²å¤„ç†çš„æ–‡ä»¶...'
                }
                processing_status['logs'].append(log_entry)
                
                files_to_process = processor._filter_files_to_process(pdf_files)
                processing_status['skipped_files'] = len(pdf_files) - len(files_to_process)
                
                if processing_status['skipped_files'] > 0:
                    log_entry = {
                        'timestamp': datetime.now().strftime('%H:%M:%S'),
                        'message': f'â­ï¸ è·³è¿‡ {processing_status["skipped_files"]} ä¸ªå·²å¤„ç†çš„æ–‡ä»¶'
                    }
                    processing_status['logs'].append(log_entry)
            else:
                files_to_process = pdf_files
                log_entry = {
                    'timestamp': datetime.now().strftime('%H:%M:%S'),
                    'message': 'ğŸ”„ å¼ºåˆ¶é‡æ–°å¤„ç†æ‰€æœ‰æ–‡ä»¶'
                }
                processing_status['logs'].append(log_entry)
            
            if not files_to_process:
                log_entry = {
                    'timestamp': datetime.now().strftime('%H:%M:%S'),
                    'message': 'âœ… æ‰€æœ‰æ–‡ä»¶éƒ½å·²å¤„ç†è¿‡'
                }
                processing_status['logs'].append(log_entry)
                processing_status['message'] = 'æ‰€æœ‰æ–‡ä»¶éƒ½å·²å¤„ç†è¿‡'
                return {'total_files': len(pdf_files), 'processed_files': 0, 'failed_files': 0, 'skipped_files': len(pdf_files)}
            
            log_entry = {
                'timestamp': datetime.now().strftime('%H:%M:%S'),
                'message': f'ğŸš€ å¼€å§‹å¤„ç† {len(files_to_process)} ä¸ªæ–‡ä»¶'
            }
            processing_status['logs'].append(log_entry)
            
            # é€ä¸ªå¤„ç†æ–‡ä»¶
            for i, pdf_file in enumerate(files_to_process):
                if processing_status['should_stop']:
                    log_entry = {
                        'timestamp': datetime.now().strftime('%H:%M:%S'),
                        'message': f'ğŸ›‘ å¤„ç†è¢«ä¸­æ–­ï¼Œå·²å®Œæˆ {i} ä¸ªæ–‡ä»¶'
                    }
                    processing_status['logs'].append(log_entry)
                    break
                
                processing_status['current_file'] = pdf_file.name
                processing_status['message'] = f'æ­£åœ¨å¤„ç†: {pdf_file.name}'
                
                log_entry = {
                    'timestamp': datetime.now().strftime('%H:%M:%S'),
                    'message': f'ğŸ“„ [{i+1}/{len(files_to_process)}] å¤„ç†: {pdf_file.name}'
                }
                processing_status['logs'].append(log_entry)
                
                try:
                    start_time = time.time()
                    processor._process_single_file(pdf_file, output_dir)
                    end_time = time.time()
                    
                    processing_status['processed_files'] += 1
                    processing_status['progress'] = int(((i + 1) / len(files_to_process)) * 100)
                    
                    log_entry = {
                        'timestamp': datetime.now().strftime('%H:%M:%S'),
                        'message': f'âœ… å®Œæˆ: {pdf_file.name} (è€—æ—¶: {end_time - start_time:.2f}s)'
                    }
                    processing_status['logs'].append(log_entry)
                    
                except Exception as e:
                    processing_status['failed_files'] += 1
                    processing_status['progress'] = int(((i + 1) / len(files_to_process)) * 100)
                    
                    log_entry = {
                        'timestamp': datetime.now().strftime('%H:%M:%S'),
                        'message': f'âŒ å¤±è´¥: {pdf_file.name} - {str(e)}'
                    }
                    processing_status['logs'].append(log_entry)
                    
                    # è®°å½•å¤±è´¥
                    try:
                        processor.file_manager.record_processing(
                            pdf_file, processor.config_hash,
                            success=False, error_message=str(e)
                        )
                    except Exception as db_e:
                        log_entry = {
                            'timestamp': datetime.now().strftime('%H:%M:%S'),
                            'message': f'âš ï¸ æ•°æ®åº“è®°å½•å¤±è´¥: {str(db_e)}'
                        }
                        processing_status['logs'].append(log_entry)
                    
                    # å¦‚æœä¸æ˜¯ä¸­æ–­ï¼Œç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªæ–‡ä»¶
                    if not processing_status['should_stop']:
                        continue
                    else:
                        break
            
            return {
                'total_files': len(pdf_files),
                'processed_files': processing_status['processed_files'],
                'failed_files': processing_status['failed_files'],
                'skipped_files': processing_status['skipped_files']
            }
        
        # ä½¿ç”¨å¢å¼ºçš„å¤„ç†æ–¹æ³•
        result = enhanced_process_directory(
            Path(input_folder),
            Path(output_folder),
            force_reprocess=force_reprocess
        )
        
        # å¤„ç†å®Œæˆæˆ–è¢«ä¸­æ–­
        if processing_status['should_stop']:
            processing_status.update({
                'is_processing': False,
                'message': 'å¤„ç†å·²è¢«ä¸­æ–­'
            })
            
            log_entry = {
                'timestamp': datetime.now().strftime('%H:%M:%S'),
                'message': f'ğŸ›‘ å¤„ç†è¢«ä¸­æ–­! æˆåŠŸ: {result["processed_files"]}, å¤±è´¥: {result["failed_files"]}, è·³è¿‡: {result["skipped_files"]}'
            }
            processing_status['logs'].append(log_entry)
        else:
            processing_status.update({
                'is_processing': False,
                'progress': 100,
                'message': 'å¤„ç†å®Œæˆ'
            })
            
            log_entry = {
                'timestamp': datetime.now().strftime('%H:%M:%S'),
                'message': f'ğŸ‰ å¤„ç†å®Œæˆ! æˆåŠŸ: {result["processed_files"]}, å¤±è´¥: {result["failed_files"]}, è·³è¿‡: {result["skipped_files"]}'
            }
            processing_status['logs'].append(log_entry)
        
    except Exception as e:
        processing_status.update({
            'is_processing': False,
            'message': f'å¤„ç†å¤±è´¥: {str(e)}'
        })
        
        log_entry = {
            'timestamp': datetime.now().strftime('%H:%M:%S'),
            'message': f'âŒ å¤„ç†å¤±è´¥: {str(e)}'
        }
        processing_status['logs'].append(log_entry)

@app.route('/status')
def get_status():
    """è·å–å¤„ç†çŠ¶æ€"""
    global processing_status
    
    # å®æ—¶æ›´æ–°è¿è¡Œæ—¶é—´
    if processing_status['is_processing'] and processing_status['start_time']:
        processing_status['elapsed_time'] = time.time() - processing_status['start_time']
    
    return jsonify(processing_status)

@app.route('/download_results')
def download_results():
    """ä¸‹è½½å¤„ç†ç»“æœ"""
    output_folder = session.get('current_output_folder')
    if not output_folder or not Path(output_folder).exists():
        return jsonify({'success': False, 'message': 'æ²¡æœ‰å¯ä¸‹è½½çš„ç»“æœ'})
    
    try:
        # åˆ›å»ºZIPæ–‡ä»¶
        memory_file = io.BytesIO()
        with zipfile.ZipFile(memory_file, 'w', zipfile.ZIP_DEFLATED) as zipf:
            output_path = Path(output_folder)
            for file_path in output_path.rglob('*'):
                if file_path.is_file():
                    # è®¡ç®—ç›¸å¯¹è·¯å¾„
                    relative_path = file_path.relative_to(output_path)
                    zipf.write(file_path, relative_path)
        
        memory_file.seek(0)
        
        filename = f"pdf_processing_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip"
        
        return send_file(
            memory_file,
            as_attachment=True,
            download_name=filename,
            mimetype='application/zip'
        )
        
    except Exception as e:
        return jsonify({'success': False, 'message': f'ä¸‹è½½å¤±è´¥: {str(e)}'})

@app.route('/open_output_folder', methods=['POST'])
def open_output_folder():
    """æ‰“å¼€è¾“å‡ºæ–‡ä»¶å¤¹"""
    try:
        output_folder = processing_status.get('output_folder') or session.get('current_output_folder')
        if not output_folder or not Path(output_folder).exists():
            return jsonify({'success': False, 'message': 'è¾“å‡ºæ–‡ä»¶å¤¹ä¸å­˜åœ¨'})
        
        # è·¨å¹³å°æ‰“å¼€æ–‡ä»¶å¤¹
        import subprocess
        import platform
        
        if platform.system() == 'Windows':
            os.startfile(output_folder)
        elif platform.system() == 'Darwin':  # macOS
            subprocess.Popen(['open', output_folder])
        else:  # Linux
            subprocess.Popen(['xdg-open', output_folder])
        
        return jsonify({'success': True, 'message': 'å·²æ‰“å¼€è¾“å‡ºæ–‡ä»¶å¤¹'})
        
    except Exception as e:
        return jsonify({'success': False, 'message': f'æ‰“å¼€å¤±è´¥: {str(e)}'})

@app.route('/history')
def history():
    """å¤„ç†å†å²é¡µé¢"""
    file_manager = FileManager()
    history_data = file_manager.get_processing_history(50)
    stats = file_manager.get_statistics()
    return render_template('history.html', history=history_data, stats=stats)

@app.route('/cleanup')
def cleanup():
    """æ¸…ç†é¡µé¢"""
    return render_template('cleanup.html')

@app.route('/cleanup_old', methods=['POST'])
def cleanup_old():
    """æ¸…ç†æ—§è®°å½•"""
    try:
        days = int(request.form.get('days', 30))
        file_manager = FileManager()
        count = file_manager.cleanup_old_records(days)
        flash(f'æˆåŠŸæ¸…ç†äº† {count} æ¡å¤±è´¥è®°å½•')
        return redirect(url_for('cleanup'))
    except Exception as e:
        flash(f'æ¸…ç†å¤±è´¥: {str(e)}')
        return redirect(url_for('cleanup'))

@app.route('/clear_uploads', methods=['POST'])
def clear_uploads():
    """æ¸…ç©ºä¸Šä¼ æ–‡ä»¶å¤¹"""
    try:
        upload_folder = Path(app.config['UPLOAD_FOLDER'])
        if upload_folder.exists():
            shutil.rmtree(upload_folder)
            upload_folder.mkdir(exist_ok=True)
        flash('ä¸Šä¼ æ–‡ä»¶å¤¹å·²æ¸…ç©º')
        return redirect(url_for('cleanup'))
    except Exception as e:
        flash(f'æ¸…ç©ºå¤±è´¥: {str(e)}')
        return redirect(url_for('cleanup'))

@app.route('/clear_outputs', methods=['POST'])
def clear_outputs():
    """æ¸…ç©ºè¾“å‡ºæ–‡ä»¶å¤¹"""
    try:
        output_folder = Path(app.config['OUTPUT_FOLDER'])
        if output_folder.exists():
            shutil.rmtree(output_folder)
            output_folder.mkdir(exist_ok=True)
        flash('è¾“å‡ºæ–‡ä»¶å¤¹å·²æ¸…ç©º')
        return redirect(url_for('cleanup'))
    except Exception as e:
        flash(f'æ¸…ç©ºå¤±è´¥: {str(e)}')
        return redirect(url_for('cleanup'))

if __name__ == '__main__':
    print("ğŸš€ å¯åŠ¨å¢å¼ºç‰ˆFlask PDFå¤„ç†å™¨Webç•Œé¢")
    print("ğŸ“ è¯·åœ¨æµè§ˆå™¨ä¸­è®¿é—®: http://localhost:5000")
    print("ğŸ”§ ä½¿ç”¨Ctrl+Cåœæ­¢æœåŠ¡å™¨")
    
    # å¼€å‘ç¯å¢ƒé…ç½®
    app.run(debug=True, host='0.0.0.0', port=5000)
