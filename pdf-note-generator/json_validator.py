
# json_validator.py - æ”¹è¿›ç‰ˆæœ¬
import json
import os
import sys
from typing import Dict, List, Tuple, Optional, Any
from pathlib import Path
import logging
import re

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class JSONValidator:
    def __init__(self):
        # å¿…éœ€å­—æ®µå®šä¹‰
        self.required_fields = {
            'file_name': str,
            'generated_at': str,
            'structured_info': dict
        }
        
        # structured_info å¿…éœ€å­—æ®µ
        self.structured_info_required = {
            'title_cn': str,
            'title_en': str,
            'authors': list,
            'abstract': str,
            'publication_year': str
        }
        
        # å¯é€‰ä½†é‡è¦çš„å­—æ®µ
        self.optional_important_fields = {
            'category': str,
            'topics': list,
            'keywords': list,
            'venue': str,
            'doi': str,
            'methodology': str,
            'conclusion': str
        }
        
        # çœŸæ­£çš„é”™è¯¯æ¨¡å¼ï¼ˆæ›´ç²¾ç¡®çš„åŒ¹é…ï¼‰
        self.error_patterns = [
            r'^error\s*:',  # ä»¥"error:"å¼€å¤´
            r'^failed\s*:',  # ä»¥"failed:"å¼€å¤´
            r'^unable to process',  # ä»¥"unable to process"å¼€å¤´
            r'^could not extract',  # ä»¥"could not extract"å¼€å¤´
            r'extraction failed',  # æå–å¤±è´¥
            r'error processing file',  # æ–‡ä»¶å¤„ç†é”™è¯¯
            r'failed to parse',  # è§£æå¤±è´¥
            r'unable to read',  # è¯»å–å¤±è´¥
            r'no content found',  # æœªæ‰¾åˆ°å†…å®¹
            r'invalid pdf',  # æ— æ•ˆPDF
            r'corrupted file',  # æŸåæ–‡ä»¶
            r'processing error',  # å¤„ç†é”™è¯¯
            r'timeout.*processing',  # å¤„ç†è¶…æ—¶
        ]
        
        # å­¦æœ¯å†…å®¹ä¸­çš„å¸¸è§æ­£å¸¸ç”¨è¯ï¼ˆç™½åå•ï¼‰
        self.academic_whitelist = [
            'failed to achieve',
            'unable to solve',
            'failed to converge',
            'unable to detect',
            'failed to establish',
            'unable to identify',
            'failed to improve',
            'unable to handle',
            'could not be found',
            'could not be determined',
            'could not be achieved',
            'error rate',
            'error analysis',
            'error correction',
            'error detection',
            'failure analysis',
            'failure mode',
            'failure detection',
        ]
    
    def validate_json_structure(self, data: Dict[str, Any]) -> Tuple[bool, List[str]]:
        """éªŒè¯JSONç»“æ„æ˜¯å¦åˆè§„"""
        errors = []
        
        # æ£€æŸ¥é¡¶çº§å¿…éœ€å­—æ®µ
        for field, field_type in self.required_fields.items():
            if field not in data:
                errors.append(f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
                continue
            
            if not isinstance(data[field], field_type):
                errors.append(f"å­—æ®µç±»å‹é”™è¯¯: {field} åº”è¯¥æ˜¯ {field_type.__name__}")
        
        # æ£€æŸ¥structured_infoå­—æ®µ
        if 'structured_info' in data:
            structured_info = data['structured_info']
            
            for field, field_type in self.structured_info_required.items():
                if field not in structured_info:
                    errors.append(f"structured_infoç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
                    continue
                
                if not isinstance(structured_info[field], field_type):
                    errors.append(f"structured_infoå­—æ®µç±»å‹é”™è¯¯: {field} åº”è¯¥æ˜¯ {field_type.__name__}")
        
        return len(errors) == 0, errors
    
    def is_real_error(self, text: str) -> bool:
        """åˆ¤æ–­æ–‡æœ¬æ˜¯å¦åŒ…å«çœŸæ­£çš„é”™è¯¯ä¿¡æ¯"""
        text_lower = text.lower()
        
        # é¦–å…ˆæ£€æŸ¥æ˜¯å¦åœ¨ç™½åå•ä¸­ï¼ˆå­¦æœ¯ç”¨è¯ï¼‰
        for whitelist_phrase in self.academic_whitelist:
            if whitelist_phrase.lower() in text_lower:
                return False
        
        # æ£€æŸ¥æ˜¯å¦åŒ¹é…é”™è¯¯æ¨¡å¼
        for pattern in self.error_patterns:
            if re.search(pattern, text_lower):
                return True
        
        # æ£€æŸ¥ç‰¹å®šçš„é”™è¯¯ä¸Šä¸‹æ–‡
        error_contexts = [
            'error occurred while',
            'failed during processing',
            'unable to complete',
            'extraction process failed',
            'parsing error',
            'file corruption',
            'invalid format',
            'processing timeout',
            'memory error',
            'io error',
            'network error',
            'permission denied',
            'access denied',
            'file not found',
            'directory not found',
        ]
        
        for context in error_contexts:
            if context in text_lower:
                return True
        
        return False
    
    def validate_content_quality(self, data: Dict[str, Any]) -> Tuple[bool, List[str]]:
        """éªŒè¯å†…å®¹è´¨é‡"""
        warnings = []
        errors = []
        
        if 'structured_info' not in data:
            errors.append("æ²¡æœ‰structured_infoå­—æ®µ")
            return False, errors
        
        info = data['structured_info']
        
        # æ£€æŸ¥å…³é”®å†…å®¹æ˜¯å¦æœ‰æ•ˆ
        if 'title_en' in info:
            title_en = str(info['title_en']).strip()
            if not title_en or len(title_en) < 5:
                errors.append("è‹±æ–‡æ ‡é¢˜å¤ªçŸ­æˆ–ä¸ºç©º")
            elif self.is_real_error(title_en):
                errors.append(f"è‹±æ–‡æ ‡é¢˜åŒ…å«é”™è¯¯ä¿¡æ¯: {title_en[:50]}...")
        
        if 'title_cn' in info:
            title_cn = str(info['title_cn']).strip()
            if not title_cn or len(title_cn) < 3:
                warnings.append("ä¸­æ–‡æ ‡é¢˜å¤ªçŸ­æˆ–ä¸ºç©º")
            elif self.is_real_error(title_cn):
                errors.append(f"ä¸­æ–‡æ ‡é¢˜åŒ…å«é”™è¯¯ä¿¡æ¯: {title_cn[:50]}...")
        
        if 'authors' in info:
            authors = info['authors']
            if not authors or len(authors) == 0:
                errors.append("ä½œè€…åˆ—è¡¨ä¸ºç©º")
            elif isinstance(authors, list) and len(authors) > 0:
                # æ£€æŸ¥ä½œè€…æ˜¯å¦æœ‰æ•ˆ
                valid_authors = []
                for author in authors:
                    if author and isinstance(author, str) and len(str(author).strip()) > 0:
                        if not self.is_real_error(str(author)):
                            valid_authors.append(author)
                
                if len(valid_authors) == 0:
                    errors.append("æ²¡æœ‰æœ‰æ•ˆçš„ä½œè€…ä¿¡æ¯")
        
        if 'abstract' in info:
            abstract = str(info['abstract']).strip()
            if not abstract or len(abstract) < 50:
                errors.append("æ‘˜è¦å¤ªçŸ­æˆ–ä¸ºç©º")
            elif self.is_real_error(abstract):
                errors.append(f"æ‘˜è¦åŒ…å«é”™è¯¯ä¿¡æ¯: {abstract[:100]}...")
        
        if 'publication_year' in info:
            year = info['publication_year']
            if isinstance(year, str):
                if not year.strip() or not year.strip().isdigit():
                    warnings.append("å‘è¡¨å¹´ä»½æ ¼å¼ä¸æ­£ç¡®")
                else:
                    year_int = int(year.strip())
                    if year_int < 1900 or year_int > 2030:
                        warnings.append(f"å‘è¡¨å¹´ä»½ä¸åˆç†: {year_int}")
        
        # æ£€æŸ¥é¡¶çº§å­—æ®µæ˜¯å¦åŒ…å«é”™è¯¯ä¿¡æ¯
        if 'file_name' in data:
            file_name = str(data['file_name'])
            if self.is_real_error(file_name):
                errors.append(f"æ–‡ä»¶ååŒ…å«é”™è¯¯ä¿¡æ¯: {file_name}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ˜æ˜¾çš„é”™è¯¯æ ‡è¯†ç¬¦ï¼ˆä»…åœ¨éå†…å®¹å­—æ®µä¸­ï¼‰
        non_content_fields = ['file_name', 'generated_at', 'processing_info', 'errors']
        for field in non_content_fields:
            if field in data:
                field_text = str(data[field])
                if self.is_real_error(field_text):
                    errors.append(f"å­—æ®µ {field} åŒ…å«é”™è¯¯ä¿¡æ¯: {field_text[:100]}...")
        
        return len(errors) == 0, errors + warnings
    
    def validate_file(self, file_path: str) -> Dict[str, Any]:
        """éªŒè¯å•ä¸ªJSONæ–‡ä»¶"""
        result = {
            'file_path': file_path,
            'is_valid': False,
            'structure_valid': False,
            'content_valid': False,
            'errors': [],
            'warnings': [],
            'data': None
        }
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                result['data'] = data
            
            # éªŒè¯ç»“æ„
            structure_valid, structure_errors = self.validate_json_structure(data)
            result['structure_valid'] = structure_valid
            result['errors'].extend(structure_errors)
            
            # éªŒè¯å†…å®¹è´¨é‡
            content_valid, content_issues = self.validate_content_quality(data)
            result['content_valid'] = content_valid
            
            # åˆ†ç¦»é”™è¯¯å’Œè­¦å‘Š
            for issue in content_issues:
                if any(keyword in issue for keyword in ['é”™è¯¯', 'error', 'ç¼ºå°‘', 'ä¸ºç©º', 'å¤ªçŸ­', 'åŒ…å«é”™è¯¯ä¿¡æ¯']):
                    result['errors'].append(issue)
                else:
                    result['warnings'].append(issue)
            
            result['is_valid'] = structure_valid and content_valid
            
        except json.JSONDecodeError as e:
            result['errors'].append(f"JSONæ ¼å¼é”™è¯¯: {str(e)}")
        except Exception as e:
            result['errors'].append(f"æ–‡ä»¶è¯»å–é”™è¯¯: {str(e)}")
        
        return result
    
    def validate_folder(self, folder_path: str) -> Dict[str, Any]:
        """éªŒè¯æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰JSONæ–‡ä»¶"""
        folder_path = Path(folder_path)
        
        if not folder_path.exists():
            return {
                'error': f"æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {folder_path}",
                'results': []
            }
        
        json_files = list(folder_path.glob('*.json'))
        results = []
        
        print(f"ğŸ” å¼€å§‹éªŒè¯ {len(json_files)} ä¸ªJSONæ–‡ä»¶...")
        
        for i, json_file in enumerate(json_files):
            if i % 10 == 0 and i > 0:
                print(f"è¿›åº¦: {i}/{len(json_files)}")
            
            result = self.validate_file(str(json_file))
            results.append(result)
        
        # ç»Ÿè®¡ç»“æœ
        total_files = len(results)
        valid_files = sum(1 for r in results if r['is_valid'])
        invalid_files = total_files - valid_files
        
        summary = {
            'total_files': total_files,
            'valid_files': valid_files,
            'invalid_files': invalid_files,
            'success_rate': valid_files / total_files * 100 if total_files > 0 else 0,
            'results': results
        }
        
        return summary
    
    def test_error_detection(self) -> None:
        """æµ‹è¯•é”™è¯¯æ£€æµ‹åŠŸèƒ½"""
        test_cases = [
            # çœŸæ­£çš„é”™è¯¯
            ("Error: Failed to process PDF file", True),
            ("Failed to extract text from document", True),
            ("Unable to parse document structure", True),
            ("Processing error occurred", True),
            ("Extraction failed due to corruption", True),
            
            # æ­£å¸¸çš„å­¦æœ¯å†…å®¹
            ("Failed to achieve convergence in optimization", False),
            ("Unable to solve the NP-hard problem", False),
            ("The algorithm failed to improve performance", False),
            ("Error rate analysis shows improvements", False),
            ("Failure detection mechanism proposed", False),
            ("Could not be determined without additional data", False),
            ("The system was unable to handle large datasets", False),
            ("Performance degradation failed to meet expectations", False),
        ]
        
        print("ğŸ§ª æµ‹è¯•é”™è¯¯æ£€æµ‹åŠŸèƒ½:")
        for text, expected in test_cases:
            result = self.is_real_error(text)
            status = "âœ…" if result == expected else "âŒ"
            print(f"{status} '{text[:50]}...' -> {result} (é¢„æœŸ: {expected})")
    
    def organize_files(self, source_folder: str, success_folder: str, failure_folder: str) -> Dict[str, Any]:
        """å°†JSONæ–‡ä»¶æŒ‰éªŒè¯ç»“æœåˆ†ç±»åˆ°ä¸åŒæ–‡ä»¶å¤¹"""
        import shutil
        
        # åˆ›å»ºç›®æ ‡æ–‡ä»¶å¤¹
        Path(success_folder).mkdir(parents=True, exist_ok=True)
        Path(failure_folder).mkdir(parents=True, exist_ok=True)
        
        # éªŒè¯æ–‡ä»¶å¤¹
        validation_results = self.validate_folder(source_folder)
        
        if 'error' in validation_results:
            return validation_results
        
        moved_files = {'success': [], 'failure': []}
        
        for result in validation_results['results']:
            source_path = Path(result['file_path'])
            
            if result['is_valid']:
                # ç§»åŠ¨åˆ°æˆåŠŸæ–‡ä»¶å¤¹
                dest_path = Path(success_folder) / source_path.name
                shutil.move(str(source_path), str(dest_path))
                moved_files['success'].append(str(dest_path))
            else:
                # ç§»åŠ¨åˆ°å¤±è´¥æ–‡ä»¶å¤¹
                dest_path = Path(failure_folder) / source_path.name
                shutil.move(str(source_path), str(dest_path))
                moved_files['failure'].append(str(dest_path))
        
        return {
            'summary': validation_results,
            'moved_files': moved_files
        }
    
    def generate_report(self, validation_results: Dict[str, Any], output_file: Optional[str] = None) -> str:
        """ç”ŸæˆéªŒè¯æŠ¥å‘Š"""
        if 'error' in validation_results:
            return f"éªŒè¯å¤±è´¥: {validation_results['error']}"
        
        report_lines = []
        report_lines.append("=" * 60)
        report_lines.append("ğŸ“‹ JSONæ–‡ä»¶éªŒè¯æŠ¥å‘Š")
        report_lines.append("=" * 60)
        
        # æ€»ä½“ç»Ÿè®¡
        report_lines.append(f"ğŸ“Š æ€»ä½“ç»Ÿè®¡:")
        report_lines.append(f"  - æ€»æ–‡ä»¶æ•°: {validation_results['total_files']}")
        report_lines.append(f"  - æœ‰æ•ˆæ–‡ä»¶: {validation_results['valid_files']}")
        report_lines.append(f"  - æ— æ•ˆæ–‡ä»¶: {validation_results['invalid_files']}")
        report_lines.append(f"  - æˆåŠŸç‡: {validation_results['success_rate']:.1f}%")
        report_lines.append("")
        
        # æ— æ•ˆæ–‡ä»¶è¯¦æƒ…
        if validation_results['invalid_files'] > 0:
            report_lines.append("âŒ æ— æ•ˆæ–‡ä»¶è¯¦æƒ…:")
            for result in validation_results['results']:
                if not result['is_valid']:
                    report_lines.append(f"  ğŸ“„ {Path(result['file_path']).name}")
                    for error in result['errors']:
                        report_lines.append(f"    - âŒ {error}")
                    for warning in result['warnings']:
                        report_lines.append(f"    - âš ï¸ {warning}")
                    report_lines.append("")
        
        # ç»Ÿè®¡ä¸åŒç±»å‹çš„é”™è¯¯
        error_types = {}
        for result in validation_results['results']:
            if not result['is_valid']:
                for error in result['errors']:
                    error_type = error.split(':')[0] if ':' in error else error.split(' ')[0]
                    error_types[error_type] = error_types.get(error_type, 0) + 1
        
        if error_types:
            report_lines.append("ğŸ“ˆ é”™è¯¯ç±»å‹ç»Ÿè®¡:")
            for error_type, count in sorted(error_types.items(), key=lambda x: x[1], reverse=True):
                report_lines.append(f"  - {error_type}: {count} æ¬¡")
            report_lines.append("")
        
        report_text = "\n".join(report_lines)
        
        if output_file:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(report_text)
            print(f"ğŸ“„ æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}")
        
        return report_text

def main():
    """å‘½ä»¤è¡Œæ¥å£"""
    import argparse
    
    parser = argparse.ArgumentParser(description='JSONæ–‡ä»¶éªŒè¯å™¨ - æ”¹è¿›ç‰ˆ')
    parser.add_argument('action', choices=['validate', 'organize', 'report', 'test'], 
                       help='æ“ä½œç±»å‹')
    parser.add_argument('--source', '-s', 
                       help='æºæ–‡ä»¶å¤¹è·¯å¾„')
    parser.add_argument('--success', help='æˆåŠŸæ–‡ä»¶å¤¹è·¯å¾„ï¼ˆä»…ç”¨äºorganizeï¼‰')
    parser.add_argument('--failure', help='å¤±è´¥æ–‡ä»¶å¤¹è·¯å¾„ï¼ˆä»…ç”¨äºorganizeï¼‰')
    parser.add_argument('--output', '-o', help='æŠ¥å‘Šè¾“å‡ºæ–‡ä»¶è·¯å¾„')
    
    args = parser.parse_args()
    
    validator = JSONValidator()
    
    if args.action == 'test':
        validator.test_error_detection()
        return
    
    if not args.source:
        print("âŒ éœ€è¦æŒ‡å®šæºæ–‡ä»¶å¤¹è·¯å¾„ --source")
        return
    
    if args.action == 'validate':
        results = validator.validate_folder(args.source)
        if 'error' in results:
            print(f"âŒ éªŒè¯å¤±è´¥: {results['error']}")
        else:
            print(f"\nâœ… éªŒè¯å®Œæˆ: {results['success_rate']:.1f}% é€šè¿‡ç‡")
            print(f"  - æ€»æ–‡ä»¶æ•°: {results['total_files']}")
            print(f"  - æœ‰æ•ˆæ–‡ä»¶: {results['valid_files']}")
            print(f"  - æ— æ•ˆæ–‡ä»¶: {results['invalid_files']}")
        
    elif args.action == 'organize':
        if not args.success or not args.failure:
            print("âŒ organizeæ“ä½œéœ€è¦æŒ‡å®š --success å’Œ --failure å‚æ•°")
            return
        
        results = validator.organize_files(args.source, args.success, args.failure)
        if 'error' in results:
            print(f"âŒ æ•´ç†å¤±è´¥: {results['error']}")
        else:
            print(f"\nâœ… æ–‡ä»¶æ•´ç†å®Œæˆ:")
            print(f"  - æˆåŠŸæ–‡ä»¶: {len(results['moved_files']['success'])}")
            print(f"  - å¤±è´¥æ–‡ä»¶: {len(results['moved_files']['failure'])}")
        
    elif args.action == 'report':
        results = validator.validate_folder(args.source)
        if 'error' in results:
            print(f"âŒ ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {results['error']}")
        else:
            report = validator.generate_report(results, args.output)
            if not args.output:
                print(report)

if __name__ == '__main__':
    main()
